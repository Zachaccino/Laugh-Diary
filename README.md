# Laugh Diary

This is a team project with Tim Bunnage and Benjamin De Worsop. 

This is an app that remembers moments that make you laughs and relive the moments later.

The laugh detection model is trained using our own voices and deployed to the app using a tensorflow model, meaning the detection is performed on-device, without the need for external server. It comes with a dynamic interface showing the recording status. The app contains a laugh gallery which the context is translated to text for easier browsing and finding. In the gallery, you can play the moments that made you laugh. Finally, a dashboard that shows your happiness over a period of time.


# My Contributions

I am responsible for designing, implementing, training, and transferring a CNN model that recognises laughs using MFCC.

I took part in the design and implementation of data visualisation, live translation, geo tagging, and implemented a dynamic sound visualiser for the voice recognition interface. 

I integrated the sound recording and playback system in the app.

# Screenshots

The diary recording interface.

![image](https://user-images.githubusercontent.com/38675169/159159470-67b747c5-edd3-4825-9ef4-320f2ec994c1.png)

The gallery.

![image](https://user-images.githubusercontent.com/38675169/159159513-42895574-ae4c-434a-86e1-b5d29477ecb1.png)

The diary player.

![image](https://user-images.githubusercontent.com/38675169/159159528-51111764-985f-4d5d-8c58-edafd3916d28.png)

The dashboard.

![image](https://user-images.githubusercontent.com/38675169/159159538-5f225171-2ca8-4528-bfb9-f33ff9cf977d.png)
